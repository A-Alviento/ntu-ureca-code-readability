{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d202efb2",
   "metadata": {},
   "source": [
    "# Feature generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14168bb0",
   "metadata": {},
   "source": [
    "Halstead Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb4eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import log2\n",
    "\n",
    "def halstead_volume(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        code = file.read()\n",
    "\n",
    "    # Remove comments from the code\n",
    "    code = re.sub(r'//.*', '', code) # Remove single-line comments\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL) # Remove multi-line comments\n",
    "\n",
    "    # Split the code into lines and filter out lines that do not contain any operators\n",
    "    lines = [line for line in code.split('\\n') if any(op in line for op in '+-*/%=><&|^!~')]\n",
    "\n",
    "    # Count the number of unique operators and operands in the code\n",
    "    operators = set(re.findall(r'[\\+\\-\\*/%=><&\\|\\^!~]+', code))\n",
    "    operands = set(re.findall(r'[a-zA-Z]\\w*', code))\n",
    "\n",
    "    # Calculate the total number of operators and operands in the code\n",
    "    total_operators = sum(code.count(op) for op in operators)\n",
    "    total_operands = sum(code.count(op) for op in operands)\n",
    "\n",
    "    # Calculate the program vocabulary (total number of unique operators and operands)\n",
    "    program_vocab = len(operators) + len(operands)\n",
    "\n",
    "    # Calculate the program length (total number of operators and operands)\n",
    "    program_length = total_operators + total_operands\n",
    "\n",
    "    # Calculate the program volume using the Halstead volume formula\n",
    "    program_volume = program_length * log2(program_vocab)\n",
    "\n",
    "    return program_volume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "869d1740",
   "metadata": {},
   "source": [
    "Number of lines, number of blank lines, number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24370d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 0, 504)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_source_lines_chars(file_path):\n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Initialize a counter variable to keep track of the number of source code lines\n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        # keep count of end blank lines\n",
    "        count2 = 0\n",
    "        # check if this is the first non-blank line\n",
    "        firstNonBlank = False\n",
    "        chars = 0\n",
    "\n",
    "\n",
    "        # Loop through each line in the file\n",
    "        for line in f:\n",
    "            # Check if the line is blank line\n",
    "            if line.strip() == '':\n",
    "                if firstNonBlank:\n",
    "                    count1 += 1 \n",
    "                    count2 += 1 \n",
    "                continue\n",
    "            # If the line is not a blank line, increment the counter\n",
    "            else:\n",
    "                count += 1\n",
    "                chars += len(line)\n",
    "                count2 = 0\n",
    "                firstNonBlank = True\n",
    "\n",
    "        # Return the number of source code lines\n",
    "        return count, count1 - count2, chars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e419796",
   "metadata": {},
   "source": [
    "Number of comments and Ratio of comments to total number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1e1965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.125)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_comment(file_path):\n",
    "    # Initialize counters for total lines and comment lines\n",
    "    total_lines = 0\n",
    "    comment_lines = 0\n",
    "\n",
    "    # Open the file for reading\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Iterate through each line in the file\n",
    "        for line in file:\n",
    "            # Strip leading and trailing whitespaces from the line\n",
    "            line = line.strip()\n",
    "            # Increment the total lines counter\n",
    "            total_lines += 1\n",
    "\n",
    "             # If the line starts with \"//\", it is a single line comment\n",
    "            if line.startswith(\"//\"):\n",
    "                comment_lines += 1\n",
    "\n",
    "            # If the line starts with \"/*\", it is the beginning of a multi-line comment\n",
    "            elif line.startswith(\"/*\"):\n",
    "                comment_lines += 1\n",
    "                 # Keep reading lines until the end of the multi-line comment \"*/\" is reached\n",
    "                while \"*/\" not in line:\n",
    "                    line = next(file).strip()\n",
    "                    total_lines += 1\n",
    "                    comment_lines += 1\n",
    "\n",
    "            # If the line contains \"/*\" but not \"*/\", it is the middle of a multi-line comment\n",
    "            elif \"/*\" in line and \"*/\" not in line:\n",
    "                comment_lines += 1\n",
    "                # Keep reading lines until the end of the multi-line comment \"*/\" is reached\n",
    "                while \"*/\" not in line:\n",
    "                    line = next(file).strip()\n",
    "                    total_lines += 1\n",
    "                    comment_lines += 1\n",
    "                # Increment the comment lines counter to include the end of the multi-line comment \"*/\"\n",
    "                comment_lines += 1\n",
    "                \n",
    "    # Return both the total number of comment lines and the average number of comments per line\n",
    "    return comment_lines, comment_lines/total_lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d53f004d",
   "metadata": {},
   "source": [
    "Code readability (FK and GF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54cc382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.614285714285714, 21.93660714285717)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to estimate the number of syllables in a given word\n",
    "def count_syllables(word):\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    # Loop through each character in the word\n",
    "    for char in word.lower():\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "    \n",
    "    # If the word ends with 'e', subtract one from the syllable count\n",
    "    if word.lower().endswith('e'):\n",
    "        count -= 1\n",
    "    # If the word has no vowels, set the count to 1\n",
    "    if count == 0:\n",
    "        count = 1\n",
    "\n",
    "    # Return the number of syllables in the word\n",
    "    return count\n",
    "\n",
    "\n",
    "# Function to calculate the readability of a text\n",
    "def readability(text):\n",
    "    # Split the text into words and sentences\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    sentences = re.findall(r'[^.!?]+[.!?]', text)\n",
    "    sentences = len(sentences)\n",
    "\n",
    "    # Create a list to store complex words (words with three or more syllables)\n",
    "    complex_words = []\n",
    "    # Calculate the total number of syllables in the text\n",
    "    totalSyllables = 0\n",
    "    \n",
    "    # If there are no sentences, set the number of sentences to 1 to avoid division by zero\n",
    "    if sentences == 0:\n",
    "        sentences = 1\n",
    "\n",
    "    # Loop through each word in the text and count the number of syllables\n",
    "    for word in words:\n",
    "        syllables = count_syllables(word)\n",
    "        totalSyllables += syllables\n",
    "\n",
    "        # If the word has three or more syllables, add it to the list of complex words\n",
    "        if (syllables >= 3):\n",
    "            complex_words.append(word)\n",
    "    \n",
    "    # Count the number of complex words in the text\n",
    "    num_complex_words = len(complex_words)\n",
    "\n",
    "    # Calculate the Gunning Fog score\n",
    "    gunningFogScore = 0.4 * (len(words) / sentences + 100 * (num_complex_words / len(words)))\n",
    "    # Calculate the Flesch-Kincaid score\n",
    "    fleschKincaidScore = 206.835 - 1.015*(len(words)/sentences) - 84.6*(totalSyllables/len(words))\n",
    "\n",
    "    # Return the readability scores\n",
    "    return gunningFogScore, fleschKincaidScore\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the average readability of a file containing multiple comments\n",
    "def average_readability(file_path):\n",
    "    # Create a list to store the readability scores of each comment\n",
    "    scores = []\n",
    "\n",
    "    # Open the file containing the comments\n",
    "    with open(file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "        # Extract all the comments from the file\n",
    "        comments = re.findall(r'(?:/\\*(?:[^*]|(?:\\*+[^*/]))*\\*+/)|(?://.*)', text)\n",
    "\n",
    "        # If there are no comments in the file, return a default score\n",
    "        if not comments:\n",
    "            return 20, 0\n",
    "\n",
    "        # Loop through each comment in the file and calculate its readability score\n",
    "        for comment in comments:\n",
    "            # Only consider comments that contain at least one word\n",
    "            if (len(re.findall(r'\\b\\w+\\b', comment)) != 0):\n",
    "                scores.append(readability(comment))\n",
    "\n",
    "        # If no comments meet the criteria, return a default score\n",
    "        if (len(scores) == 0):\n",
    "            return 20, 0\n",
    "\n",
    "        readabilityGF = 0\n",
    "        readabilityFK = 0\n",
    "        # Calculate the average readability scores of all the comments\n",
    "        for score in scores:\n",
    "            readabilityGF += score[0]\n",
    "            readabilityFK += score[1]\n",
    "\n",
    "        # Return the average readability scores\n",
    "        return readabilityGF/len(scores), readabilityFK/len(scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84307701",
   "metadata": {},
   "source": [
    "Number of identifiers, Number of identifiers containing english words, Number of unique identifiers, Number of unique identifiers containing english words, Number of meaningful identifiers, Average length of identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3526f8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 25, 19, 16, 10, 5.862068965517241)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "import keyword\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import spellchecker\n",
    "\n",
    "# List of Java keywords\n",
    "java_keywords = [\"abstract\", \"continue\", \"for\", \"new\", \"switch\", \"assert\", \"default\", \"goto\", \"package\", \"synchronized\", \"boolean\", \"do\", \"if\", \"private\", \"this\", \"break\", \"double\", \"implements\", \"protected\", \"throw\", \"byte\", \"else\", \"import\", \"public\", \"throws\", \"case\", \"enum\", \"instanceof\", \"return\", \"transient\", \"catch\", \"extends\", \"int\", \"short\", \"try\", \"char\", \"final\", \"interface\", \"static\", \"void\", \"class\", \"finally\", \"long\", \"strictfp\", \"volatile\", \"const\", \"float\", \"native\", \"super\", \"while\", \"Object\", \"null\", \"true\", \"false\"]\n",
    "\n",
    "\n",
    "\n",
    "# This function checks if a given word is in english dictionary\n",
    "def contains_in_vocab(word):\n",
    "    # Split the line into words based on capital letters\n",
    "    words = re.findall(r\"[A-Z]?[a-z]+|'[^']+'|\\\"[^\\\"]+\\\"\", word)\n",
    "    tokens = []\n",
    "\n",
    "    for word in words:\n",
    "        # Check if word is enclosed in quotes\n",
    "        if not (word.startswith(\"'\") and word.endswith(\"'\") or word.startswith('\"') and word.endswith('\"')):\n",
    "            # Tokenize the word if it's not enclosed in quotes\n",
    "            tokens.extend(tokenize.tokenize(BytesIO(word.encode(\"utf-8\")).readline))\n",
    "    \n",
    "    for token_type, token_string, _, _, _ in tokens:\n",
    "        spell = spellchecker.SpellChecker()\n",
    "        if (spell.correction(token_string) == token_string):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# This function tokenizes a given line of code\n",
    "def tokenizeLine(line):    \n",
    "    # Split the line into words based on non-alphanumeric characters\n",
    "    words = re.findall(r\"[A-Za-z]+|'[^']+'|\\\"[^\\\"]+\\\"\", line)\n",
    "    tokens = []\n",
    "    for word in words:\n",
    "        if not (word.startswith(\"'\") and word.endswith(\"'\") or word.startswith('\"') and word.endswith('\"')):\n",
    "            tokens.extend(tokenize.tokenize(BytesIO(word.encode(\"utf-8\")).readline))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "# This function counts the number of identifiers, English identifiers, unique identifiers, unique English identifiers, \n",
    "# and identifiers with length between 6 and 9 characters in a given file.\n",
    "def identifiers(file_path):\n",
    "    # Read the file\n",
    "    with open(file_path, \"r\") as file:\n",
    "        code = file.read()\n",
    "    \n",
    "    # Initialize variables\n",
    "    lines = code.split(\"\\n\")\n",
    "    identifiers_eng = []\n",
    "    identifier_set = []\n",
    "    numId6_9 = 0\n",
    "    id_len = []\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = tokenizeLine(line)\n",
    "        \n",
    "        # Check if the token is an identifier and not a Java keyword\n",
    "        for token_type, token_string, _, _, _ in tokens:\n",
    "            if token_type == tokenize.NAME and token_string not in java_keywords:\n",
    "                identifier_set.append(token_string)\n",
    "                id_len.append(len(token_string))\n",
    "\n",
    "                # Check if the identifier is an English word\n",
    "                if (contains_in_vocab(token_string)):\n",
    "                    identifiers_eng.append(token_string)\n",
    "                # Check if the identifier has length between 6 and 9 characters\n",
    "                if (len(token_string) <= 9 and len(token_string) >= 6):\n",
    "                    numId6_9 += 1\n",
    "    \n",
    "    # Count the number of unique identifiers and unique English identifiers\n",
    "    unique_identifiers = set(identifier_set)\n",
    "    unique_eng_identifiers = set(identifiers_eng)\n",
    "\n",
    "    return len(identifier_set), len(identifiers_eng), len(unique_identifiers), len(unique_eng_identifiers), numId6_9, sum(id_len)/len(identifier_set)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb9257c9",
   "metadata": {},
   "source": [
    "Number of blocks of codes in the same indentation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9662864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function takes in a filepath and returns the number of indentation blocks in the file\n",
    "def count_blocks(filepath):\n",
    "    # Open the file and read all the lines\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Create an empty list to store the number of blocks and initialize the current block indentation to None\n",
    "    blocks = []\n",
    "    current_block_indentation = None\n",
    "    \n",
    "    # Loop through all the lines\n",
    "    for line in lines:\n",
    "        # Strip any whitespace from the beginning of the line\n",
    "        stripped_line = line.lstrip()\n",
    "        \n",
    "         # If the line is not empty\n",
    "        if stripped_line:\n",
    "            indentation = len(line) - len(stripped_line)\n",
    "            \n",
    "            # If there is no current block indentation, create a new block and add it to the list\n",
    "            if current_block_indentation is None:\n",
    "                current_block_indentation = indentation\n",
    "                blocks.append(1)\n",
    "\n",
    "            # If the current indentation is the same as the previous block, add it to that block\n",
    "            elif indentation == current_block_indentation:\n",
    "                blocks[-1] += 1\n",
    "            \n",
    "            # Otherwise, create a new block and add it to the list\n",
    "            else:\n",
    "                current_block_indentation = indentation\n",
    "                blocks.append(1)\n",
    "    \n",
    "    # Return the number of blocks\n",
    "    return len(blocks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "726df7b6",
   "metadata": {},
   "source": [
    "Max indentation length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c092031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given a file path to a Java code file, this function reads the file and \n",
    "# returns the maximum indentation length found in the file.\n",
    "def max_indentation_length(file_path):\n",
    "    # Open the file \n",
    "    with open(file_path, 'r') as f:\n",
    "        # Read all the lines of the file and store them in a list\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Initialize the maximum indentation to 0\n",
    "    max_indentation = 0\n",
    "\n",
    "    # Initialize the current indentation to 0\n",
    "    current_indentation = 0\n",
    "\n",
    "    # Loop through each line of the file\n",
    "    for line in lines:\n",
    "        # Remove any leading whitespaces from the line\n",
    "        stripped_line = line.lstrip()\n",
    "        \n",
    "        # Check if the stripped line is not empty and doesn't start with a comment\n",
    "        if stripped_line and not stripped_line.startswith('//'):\n",
    "            # Calculate the current indentation by subtracting the length of the stripped line from the length of the original line\n",
    "            current_indentation = len(line) - len(stripped_line)\n",
    "\n",
    "            # Check if the current indentation is greater than the maximum indentation\n",
    "            if current_indentation > max_indentation:\n",
    "                # Update the maximum indentation to the current indentation\n",
    "                max_indentation = current_indentation\n",
    "    \n",
    "    return max_indentation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e89035a4",
   "metadata": {},
   "source": [
    "Number of comment blocks (blocks are defined as a continuous sequence of lines that are made entirely of comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f78e5724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given a file path to a Java code file, this function reads the file and returns \n",
    "# the number of continuous comment code blocks found in the file.\n",
    "def count_comment_blocks(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Initialize variables\n",
    "    comment_block_count = 0\n",
    "    in_multi_line_block = False\n",
    "    in_pseudo_multi_line_block = False\n",
    "\n",
    "    # Loop through each line in the file\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        # Check if current line starts a multi-line comment block\n",
    "        if stripped_line.startswith('/*'):\n",
    "            in_multi_line_block = True\n",
    "            comment_block_count += 1\n",
    "\n",
    "        # Check if current line ends a multi-line comment block\n",
    "        elif stripped_line.endswith('*/'):\n",
    "            in_multi_line_block = False\n",
    "\n",
    "        # Check if current line is not a comment, but continues a multi-line block\n",
    "        elif not (stripped_line.startswith('//')):\n",
    "           in_pseudo_multi_line_block = False  \n",
    "        \n",
    "        elif in_pseudo_multi_line_block:\n",
    "            continue\n",
    "\n",
    "        # Check if current line starts a single-line comment\n",
    "        elif stripped_line.startswith('//'):\n",
    "            in_pseudo_multi_line_block = True\n",
    "            comment_block_count += 1\n",
    "\n",
    "        # Check if current line is within a multi-line comment block\n",
    "        elif in_multi_line_block:\n",
    "            comment_block_count += 1\n",
    "\n",
    "    return comment_block_count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e8a500d",
   "metadata": {},
   "source": [
    "# CSV Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa0f0026",
   "metadata": {},
   "source": [
    "Generate the matrix of features and corresponding values for the 200 code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58d44b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "subdirectory = \"Dataset/Snippets/\"\n",
    "subdirectory_path = os.path.join(current_directory, subdirectory)\n",
    "\n",
    "# Specifying the path of the directory containing the code snippets\n",
    "directory_path = subdirectory_path\n",
    "# Initializing an empty array to store the file paths\n",
    "file_path_arr = []\n",
    "\n",
    "# Using os.walk to traverse the directory structure and obtain the file paths\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in sorted(files, key=lambda x: int(os.path.splitext(x)[0])):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path_arr.append(file_path)\n",
    "\n",
    "# Initializing empty arrays to store the feature set and the feature set for each code snippet respectively\n",
    "feature_matrix = []\n",
    "feature_arr_row = []\n",
    "\n",
    "# Initializing the feature set column names\n",
    "feature_set_columns = [\"numLines\", \"numBlankLines\", \"numChars\", \"ratioBlank\", \"avgCharsLine\", \"halsteadVol\", \n",
    "                       \"ratioComment\", \"numComment\", \"commentReadabilityGF\", \"commentReadabilityFK\", \"numIdentifier\", \n",
    "                       \"numEngIdentifier\", \"numNewIdentifier\", \"numNewEngIdentifier\", \"avgNumId\", \"ratioEngIdOverId\", \n",
    "                       \"avgNewId\", \"ratioNewEngIdOverNewId\", \"numMeaningfulId\", \"ratioMeaningufulId\", \"avgIdLen\", \n",
    "                       \"numIndentBlocks\", \"ratioIndentNumLines\", \"maxIndent\", \"numCommentBlk\", \"ratioCommentBlock\"]\n",
    "\n",
    "# Iterating through each code snippet\n",
    "for i in file_path_arr:\n",
    "    # Obtaining the features of the code snippet\n",
    "    # numLines, numBlankLines, numChars, \n",
    "    # ratioBlank, avgCharsLine\n",
    "    tmp0 = count_source_lines_chars(i)\n",
    "    numLines = tmp0[0]\n",
    "    feature_arr_row.append(numLines)\n",
    "    feature_arr_row.append(tmp0[1])\n",
    "    feature_arr_row.append(tmp0[2])\n",
    "    feature_arr_row.append(tmp0[1]/numLines)\n",
    "    feature_arr_row.append(tmp0[2]/numLines)\n",
    "\n",
    "    # halsteadVol\n",
    "    feature_arr_row.append(halstead_volume(i))\n",
    "    \n",
    "    # numComment, ratioComment\n",
    "    tmp1 = calculate_comment(i)\n",
    "    feature_arr_row.append(tmp1[0])\n",
    "    feature_arr_row.append(tmp1[1])\n",
    "\n",
    "    # commentReadabilityGF, commentReadabilityFK\n",
    "    tmp2 = average_readability(i)\n",
    "    feature_arr_row.append(tmp2[0])\n",
    "    feature_arr_row.append(tmp2[1])\n",
    "    \n",
    "    # numIdentifier, numEngIdentifier, \n",
    "    # numNewIdentifier, numNewEngIdentifier\n",
    "    tmp3 = identifiers(i)\n",
    "    feature_arr_row.append(tmp3[0])\n",
    "    feature_arr_row.append(tmp3[1])\n",
    "    feature_arr_row.append(tmp3[2])\n",
    "    feature_arr_row.append(tmp3[3])\n",
    "\n",
    "    # avgNumId, ratioEngIdOverId, \n",
    "    # avgNewId, ratioNewEngIdOverNewId\n",
    "    feature_arr_row.append(tmp3[0]/numLines)\n",
    "    feature_arr_row.append(tmp3[1]/tmp3[0])\n",
    "    feature_arr_row.append(tmp3[2]/numLines)\n",
    "    feature_arr_row.append(tmp3[3]/tmp3[2])\n",
    "\n",
    "    # numMeaningfulId, ratioMeaningfulId,\n",
    "    # avgIdLen\n",
    "    feature_arr_row.append(tmp3[4])\n",
    "    feature_arr_row.append(tmp3[4]/tmp3[0])\n",
    "    feature_arr_row.append(tmp3[5])\n",
    "\n",
    "    # numIndentBlocks, ratioIndentNumLines\n",
    "    tmp4 = count_blocks(i)\n",
    "    feature_arr_row.append(tmp4)\n",
    "    feature_arr_row.append(tmp4/numLines)\n",
    "\n",
    "    # maxIndent, numCommentBlk, ratioCommentBlock\n",
    "    feature_arr_row.append(max_indentation_length(i))\n",
    "    tmp5 = count_comment_blocks(i)\n",
    "    feature_arr_row.append(tmp5)\n",
    "    feature_arr_row.append(tmp5/numLines)\n",
    "    \n",
    "    # Appending the feature set for the code snippet to the feature matrix\n",
    "    feature_matrix.append(feature_arr_row)\n",
    "    feature_arr_row = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb466766",
   "metadata": {},
   "source": [
    "Transfer matrix to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ae1f24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# generate csv from matrix features\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m feature_matrix\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfeature_matrix_1.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[1;32m      6\u001b[0m     writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(csvfile)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# generate csv from matrix features\n",
    "import csv\n",
    "\n",
    "with open(\"feature_matrix_1.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(feature_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "84f0366c652f3fb2ebfd4c253168c487a11dcf87abb2b5484248808ade3ef4e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
